{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run get_training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    \"\"\"Generate training data array for all files in \"midis_processed/\" directory.\n",
    "       \n",
    "    Returns:\n",
    "        Numpy array of training data.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for filename in os.listdir('midis_processed/')[:10]:\n",
    "        if filename.endswith(\".mid\"):\n",
    "            print(filename)\n",
    "            training_data.append(midi_to_vector('midis_processed/' + filename))\n",
    "    return np.array(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943 (1).mid\n",
      "1943-lev1 (1).mid\n",
      "1943-lev3 (1).mid\n",
      "1943-Lev3Win (1).mid\n",
      "1943boss.mid\n",
      "1943boss1.mid\n",
      "1943BossWin.mid\n",
      "1943lost (1).mid\n",
      "1943sab (1).mid\n",
      "1943won.mid\n"
     ]
    }
   ],
   "source": [
    "training_data = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(training_data[0][0])\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "training_iters = 500\n",
    "display_step = 10\n",
    "n_input = 16\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [n_input, vocab_size])\n",
    "y = tf.placeholder(\"int32\", [1, n_input])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "softmax_w = tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "softmax_b = tf.Variable(tf.random_normal([vocab_size]))\n",
    "\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tensor flow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'split:0' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:1' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:2' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:3' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:4' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:5' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:6' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:7' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:8' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:9' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:10' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:11' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:12' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:13' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:14' shape=(1, 1124) dtype=float32>,\n",
       " <tf.Tensor 'split:15' shape=(1, 1124) dtype=float32>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_split = tf.split(x, n_input, 0)\n",
    "x_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_2:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_5:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_8:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_11:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_14:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_17:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_20:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_23:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_26:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_29:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_32:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_35:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_38:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_41:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_44:0' shape=(1, 512) dtype=float32>,\n",
       " <tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_1/cell_1/basic_lstm_cell/mul_47:0' shape=(1, 512) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, states = rnn.static_rnn(rnn_cell, x_split, dtype=tf.float32)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = [tf.nn.xw_plus_b(output, softmax_w, softmax_b) for output in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(1, 16, 1124) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = tf.reshape(logits, [1, n_input, vocab_size])\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequence_loss/truediv:0' shape=(16,) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.contrib.seq2seq.sequence_loss(logits, y, weights=tf.ones([1, n_input], dtype=tf.float32), # check this\n",
    "                                        average_across_timesteps=False, average_across_batch=True)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'RMSProp' type=NoOp>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(512, 1124) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(1124,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1636, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(1024, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(2048,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), max_grad_norm)\n",
    "#grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "#optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_train_op = optimizer.apply_gradients(\n",
    "#    zip(grads, tvars),\n",
    "#    global_step=tf.train.get_or_create_global_step())\n",
    "#_train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tensor flow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midi_xy(midi_file_number):\n",
    "    offset = np.random.randint(0, len(training_data[midi_file_number]) - n_input - 1)\n",
    "    midi_x = np.array(training_data[midi_file_number])[offset:offset+n_input]\n",
    "    midi_y = np.array(training_data[midi_file_number])[1 + offset:1 + offset+n_input].dot(range(vocab_size)).reshape(1, n_input)\n",
    "    return midi_x, midi_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]), (16, 1124))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_x = np.array(training_data[0])[1:1+n_input]\n",
    "midi_x, midi_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 439,  560, 1028,  828, 1028,  724,  316, 1026,  828, 1026,  328,\n",
       "        1026,  840, 1026,  327, 1026]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_y = np.array(training_data[0])[2:2+n_input].dot(range(vocab_size)).reshape(1, n_input)\n",
    "midi_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(16, 1124) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 10, Average Loss= 900.913566\n",
      "Iter= 20, Average Loss= 464.602542\n",
      "Iter= 30, Average Loss= 244.563252\n",
      "Iter= 40, Average Loss= 173.125620\n",
      "Iter= 50, Average Loss= 172.028709\n",
      "Iter= 60, Average Loss= 191.015423\n",
      "Iter= 70, Average Loss= 300.740213\n",
      "Iter= 80, Average Loss= 319.988586\n",
      "Iter= 90, Average Loss= 401.373956\n",
      "Iter= 100, Average Loss= 346.719711\n",
      "Iter= 110, Average Loss= 364.822234\n",
      "Iter= 120, Average Loss= 359.989612\n",
      "Iter= 130, Average Loss= 356.747511\n",
      "Iter= 140, Average Loss= 331.451039\n",
      "Iter= 150, Average Loss= 395.099834\n",
      "Iter= 160, Average Loss= 522.037860\n",
      "Iter= 170, Average Loss= 513.170633\n",
      "Iter= 180, Average Loss= 562.625156\n",
      "Iter= 190, Average Loss= 452.203613\n",
      "Iter= 200, Average Loss= 457.663092\n"
     ]
    }
   ],
   "source": [
    "training_loss_list = []\n",
    "step_list = []\n",
    "with tf.Session() as session:\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    loss_total = 0\n",
    "    while step < training_iters:\n",
    "        for i in range(len(training_data)):\n",
    "            # Generate a minibatch. Add some randomness on selection process.\n",
    "            \n",
    "            midi_x, midi_y = get_midi_xy(i)\n",
    "\n",
    "            _, loss = session.run([optimizer, cost], \\\n",
    "                                                    feed_dict={x: midi_x, y: midi_y})\n",
    "            loss_total += loss\n",
    "            if (step+1) % display_step == 0:\n",
    "                print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss_total/display_step))\n",
    "                loss_total = 0\n",
    "            step_list.append(step)\n",
    "            training_loss_list.append(loss_total/display_step)\n",
    "            test = session.run([optimizer, cost], feed_dict={x: midi_x, y: midi_y})\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate music from trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "for i in range(32):\n",
    "    keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "    onehot_pred = session.run(logits, feed_dict={x: keys})\n",
    "    onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
    "    sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "    symbols_in_keys = symbols_in_keys[1:]\n",
    "    symbols_in_keys.append(onehot_pred_index)\n",
    "print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
