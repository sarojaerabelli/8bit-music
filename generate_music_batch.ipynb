{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TICKS_PER_BEAT = 480\n",
    "TEMPO = int(mido.bpm2tempo(120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run get_training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    \"\"\"Generate training data array for all files in \"midis_processed/\" directory.\n",
    "       \n",
    "    Returns:\n",
    "        Numpy array of training data.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for filename in os.listdir('midis_processed/'):\n",
    "        if filename.endswith(\".mid\"):\n",
    "            print(filename)\n",
    "            training_data.append(midi_to_vector('midis_processed/' + filename))\n",
    "    return np.array(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(num):\n",
    "    \"\"\"Generate training data array for all files in \"midis_processed/\" directory.\n",
    "       \n",
    "    Returns:\n",
    "        Numpy array of training data.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for filename in os.listdir('midis_processed/')[:num]:\n",
    "        if filename.endswith(\".mid\"):\n",
    "            vector = midi_to_vector('midis_processed/' + filename)\n",
    "            if len(vector) > 100:\n",
    "                training_data.append(vector)\n",
    "            else:\n",
    "                print(\"Faulty training data: \" + filename + \". len(vector)=\" + str(len(vector)))\n",
    "    return np.array(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set num training examples here. Note: actual number will be less, since some have errors\n",
    "training_data = get_training_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 1120)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = np.array([np.array(x) for x in training_data])\n",
    "training_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#batch_size = 100\n",
    "#learning_rate = 0.001\n",
    "#training_iters = 10000\n",
    "#n_input = 100\n",
    "#display_step = 10\n",
    "\n",
    "# number of units in RNN cell\n",
    "#n_hidden = 512\n",
    "\n",
    "# Parameters\n",
    "batch_size = 3\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "n_input = 16\n",
    "display_step = 10\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logfile_directory = 'logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logfile (NTraining=1, NHidden=1500, Batch=3, LR=0.001, Date=2017-11-09 21.03).txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logfile_name = \"Logfile (NTraining={}, NHidden={}, Batch={}, LR={}, Date={}).txt\". \\\n",
    "    format(len(training_data), n_hidden, batch_size, learning_rate, time.strftime(\"%Y-%m-%d %H.%M\"))\n",
    "logfile_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensor flow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(training_data[0][0])\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [batch_size, n_input, vocab_size])\n",
    "y = tf.placeholder(\"int32\", [batch_size, n_input])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "softmax_w = tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "softmax_b = tf.Variable(tf.random_normal([vocab_size]))\n",
    "\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph generative input\n",
    "x_generation = tf.placeholder(\"float\", [1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden), rnn.BasicLSTMCell(n_hidden)])\n",
    "x_split = tf.split(x, n_input, 1)\n",
    "x_split = [tf.reshape(a, [batch_size, vocab_size]) for a in x_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = rnn.static_rnn(rnn_cell, x_split, dtype=tf.float32)\n",
    "logits = [tf.nn.xw_plus_b(output, softmax_w, softmax_b) for output in outputs]\n",
    "logits = tf.reshape(logits, [batch_size, n_input, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.contrib.seq2seq.sequence_loss(logits, y, weights=tf.ones([batch_size, n_input], dtype=tf.float32), # check this\n",
    "                                        average_across_timesteps=True, average_across_batch=True)\n",
    "cost = tf.reduce_sum(loss)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tensor flow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_midi_xy(midi_file_number):\n",
    "    offset = np.random.randint(0, len(training_data[midi_file_number]) - n_input - 1)\n",
    "    midi_x = training_data[midi_file_number][offset:offset+n_input]\n",
    "    midi_y = training_data[midi_file_number][1 + offset:1 + offset+n_input].dot(range(vocab_size)).reshape(1, n_input)\n",
    "    return midi_x, midi_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    \"\"\"Generate random batches of x and y training vectors for RNN.\n",
    "       \n",
    "    Returns:\n",
    "        Two batches of x and y vectors.\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    batch = np.random.choice(range(len(training_data)), batch_size, replace=True)\n",
    "    for b in batch:\n",
    "        midi_x, midi_y = get_midi_xy(b%len(training_data))\n",
    "        batch_x.append(midi_x)\n",
    "        batch_y.append(midi_y)\n",
    "    batch_y = np.reshape(batch_y, [batch_size, n_input])\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seconds_to_minsecstr(seconds):\n",
    "    minutes = seconds//60\n",
    "    seconds -= 60*minutes\n",
    "    if minutes < 10: minutes = \"0\" + str(minutes)\n",
    "    if seconds < 10: seconds = \"0\" + str(seconds)\n",
    "    return str(minutes) + \":\" + str(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create log file when started training\n",
    "logfile = open(logfile_directory + logfile_name, \"w\")\n",
    "\n",
    "training_loss_list = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "step = 0\n",
    "loss_total = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while step < training_iters:\n",
    "    batch_x, batch_y = get_batch()\n",
    "\n",
    "    _, loss = session.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "    loss_total += loss\n",
    "    log = \"Iter=\" + str(step+1) + \", Average Loss={:.6f}, Time Elapsed={}\".format(loss_total/display_step, \n",
    "             seconds_to_minsecstr(int(time.time()-start_time)))\n",
    "    logfile.write(log)\n",
    "    \n",
    "    if (step+1) % display_step == 0:\n",
    "        print(log)\n",
    "        loss_total = 0\n",
    "    training_loss_list.append(loss_total/display_step)\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-44ce725505c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training loss over iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(training_loss_list)\n",
    "plt.xtitle('Iteration')\n",
    "plt.title('Training loss over iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate music from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_GENERATED_NOTE_VECTORS = 1000\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_generation, states_generation = rnn.static_rnn(rnn_cell, [x_generation], dtype=tf.float32)\n",
    "outputs_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_generation = tf.nn.xw_plus_b(outputs_generation[0], softmax_w, softmax_b)\n",
    "logits_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seed_note = np.zeros(vocab_size)\n",
    "#seed_note[0] = 1\n",
    "seed_note = training_data[int(len(training_data)*np.random.random())][0]\n",
    "seed_note = np.reshape(seed_note, [1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_music = [seed_note]\n",
    "for i in range(N_GENERATED_NOTE_VECTORS):\n",
    "    onehot_pred = session.run(logits_generation, feed_dict={x_generation: generated_music[-1]})\n",
    "    \n",
    "    next_note = np.zeros(vocab_size)\n",
    "    #index = np.argmax(onehot_pred, 1) # take max probability\n",
    "    softmax_cdf = np.exp(onehot_pred[0]/temperature)/np.sum(np.exp(onehot_pred[0]/temperature))\n",
    "    index = np.random.choice(range(vocab_size), p=softmax_cdf) # choose probabilistically\n",
    "    \n",
    "    next_note[index] = 1\n",
    "    next_note = np.reshape(next_note, [1, vocab_size])\n",
    "    \n",
    "    generated_music.append(next_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.array(generated_music).reshape(N_GENERATED_NOTE_VECTORS+1, 1124).dot(np.array(range(1124)))\n",
    "notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert generated music to midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_track_sequences(vector_sequence):\n",
    "    \"\"\"Get note sequences for each track from vector sequence output from RNN.\n",
    "\n",
    "    Args:\n",
    "       vector_sequence: List of one-hot vectors containing 128 * NUM_TRACKS note_on events, 128 * NUM_TRACKS note_off events,\n",
    "        and NUM_TIMESHIFTS timeshift events in intervals of 10 ms each.\n",
    "       \n",
    "    Returns:\n",
    "        List of track vector sequences.\n",
    "    \"\"\"\n",
    "    track_sequences = [[] for _ in range(NUM_TRACKS)]\n",
    "    start_time = 0\n",
    "    for vector in vector_sequence:\n",
    "        index = vector.index(1)\n",
    "        # vector is a time event.\n",
    "        if index >= NUM_MIDI_PITCHES * 2 * NUM_TRACKS:\n",
    "            time = (index - NUM_MIDI_PITCHES * 2 * NUM_TRACKS + 1) * TIMESHIFT_LENGTH\n",
    "            start_time += time\n",
    "        else:\n",
    "            # vector is a note_off event.\n",
    "            if index >= NUM_MIDI_PITCHES * NUM_TRACKS:\n",
    "                note_type = 'note_off'\n",
    "                index -= NUM_MIDI_PITCHES * NUM_TRACKS\n",
    "            # vector is a note_on event.\n",
    "            else:\n",
    "                note_type = 'note_on'\n",
    "            track_num = int(index / NUM_MIDI_PITCHES)\n",
    "            note = index % NUM_MIDI_PITCHES\n",
    "            track_sequences[track_num].append({\"type\": note_type, \"note\": note, \"start_time\": start_time})\n",
    "            time_delay = 0\n",
    "            \n",
    "    return track_sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_midi_from_vector_sequence(track_sequences):\n",
    "    \"\"\"Get midi from track sequences.\n",
    "\n",
    "    Args:\n",
    "       track_sequences: List of vector sequences for each track.\n",
    "       \n",
    "    Returns:\n",
    "        MidiFile object.\n",
    "    \"\"\"\n",
    "    mid = mido.MidiFile()\n",
    "    tracks = [mido.MidiTrack() for _ in range(NUM_TRACKS)]\n",
    "    mid.tracks.extend(tracks)\n",
    "\n",
    "    for i, ts in enumerate(track_sequences):\n",
    "        prev_start_time = 0\n",
    "        for event in ts:\n",
    "            time = event[\"start_time\"] - prev_start_time\n",
    "            prev_start_time = event[\"start_time\"]\n",
    "            # I picked a random number for velocity.\n",
    "            mid.tracks[i].append(mido.Message(event[\"type\"], note=event[\"note\"], velocity=50,\n",
    "                                              time=int(mido.second2tick(time, TICKS_PER_BEAT, TEMPO))))\n",
    "    \n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_sequence = get_track_sequences([list(x[0]) for x in generated_music])\n",
    "track_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = get_midi_from_vector_sequence(track_sequence)\n",
    "midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generation_output = \"generated_music/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generated Music (NTraining=1, NHidden=1500, Batch=3, LR=0.001, Length=1000, Temperature=1.5, Date=2017-11-09 21.00).txt'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_name = \"Generated Music (NTraining={}, NHidden={}, Batch={}, LR={}, Length={}, Temperature={}, Date={}).txt\". \\\n",
    "    format(len(training_data), n_hidden, batch_size, learning_rate, N_GENERATED_NOTE_VECTORS, temperature, time.strftime(\"%Y-%m-%d %H.%M\"))\n",
    "midi_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.save(generation_output + midi_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
