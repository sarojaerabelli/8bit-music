{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TICKS_PER_BEAT = 480\n",
    "TEMPO = int(mido.bpm2tempo(120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run get_training_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_VALIDATION_SET = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 2*NUM_TRACKS*NUM_MIDI_PITCHES + NUM_TIMESHIFTS\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set num training examples here. Note: actual number will be less, since some have errors\n",
    "training_data, training_data_labels = get_training_vectors_from_file('TRAINING_DATA_6000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_data = training_data[:N_VALIDATION_SET]\n",
    "validation_data_labels = training_data_labels[:N_VALIDATION_SET]\n",
    "training_data = training_data[N_VALIDATION_SET:]\n",
    "training_data_labels = training_data_labels[N_VALIDATION_SET:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 5644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bomb2stg1.mid',\n",
       " 'TNTNUNN.mid',\n",
       " 'GQOverworld.mid',\n",
       " 'RR_Music3.mid',\n",
       " 'yc_1p_music_b.mid',\n",
       " 'tmnt2stg1.mid',\n",
       " 'Sm1cave.mid']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(training_data))\n",
    "training_data_labels[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3910,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose data to create more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transpose_midi(training_example, transpose):\n",
    "    notes_transpose = training_example + transpose\n",
    "    outofbounds_mask = (notes_transpose%NUM_MIDI_PITCHES-transpose <= 0) | (notes_transpose%NUM_MIDI_PITCHES-transpose >= 128) # find notes were transposed to different tracks\n",
    "    notes_transpose -= 12*np.sign(transpose) * outofbounds_mask\n",
    "    time_mask = training_example >= 2*NUM_TRACKS*NUM_MIDI_PITCHES\n",
    "    notes_transpose = (1-time_mask)*notes_transpose + time_mask*training_example # so we don't transpose time duration 1-hot vectors\n",
    "    return notes_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transposed_training_data = []\n",
    "transpose_keys = [-4, -3, -2, 1, 1, 2, 3, 4]\n",
    "for transpose in transpose_keys: # transpose up and down up to a major third\n",
    "    for data in training_data:\n",
    "        transposed_training_data.append(transpose_midi(data, transpose))\n",
    "training_data = np.array(list(training_data) + transposed_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 50796\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''# Parameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "n_input = 64\n",
    "display_step = 200\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 512\n",
    "n_layers = 2\n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.003\n",
    "training_iters = 50000\n",
    "n_input = 80\n",
    "display_step = 100\n",
    "validation_step = 10 # every <validation_step> steps, we calculate validation error\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 100\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensor flow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [batch_size, n_input, vocab_size])\n",
    "y = tf.placeholder(\"int32\", [batch_size, n_input])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "softmax_w = tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "softmax_b = tf.Variable(tf.random_normal([vocab_size]))\n",
    "\n",
    "max_grad_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph validation input\n",
    "x_validation = tf.placeholder(\"float\", [N_VALIDATION_SET, n_input, vocab_size])\n",
    "y_validation = tf.placeholder(\"int32\", [N_VALIDATION_SET, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph generative input\n",
    "x_generation = tf.placeholder(\"float\", [1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden) for _ in range(n_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training output\n",
    "x_split = tf.unstack(x, n_input, 1)\n",
    "outputs, states = rnn.static_rnn(rnn_cell, x_split, dtype=tf.float32)\n",
    "logits = [tf.nn.xw_plus_b(output, softmax_w, softmax_b) for output in outputs]\n",
    "logits = tf.reshape(tf.split(tf.reshape(logits, [n_input, batch_size, vocab_size]), batch_size, 1), \n",
    "                    [batch_size, n_input, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loss\n",
    "loss = tf.contrib.seq2seq.sequence_loss(logits, y, weights=tf.ones([batch_size, n_input], dtype=tf.float32), # check this\n",
    "                                        average_across_timesteps=True, average_across_batch=True)\n",
    "cost = tf.reduce_sum(loss)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation output\n",
    "x_validation_split = tf.unstack(x_validation, n_input, 1)\n",
    "outputs_validation, states_validation = rnn.static_rnn(rnn_cell, x_validation_split, dtype=tf.float32)\n",
    "logits_validation = [tf.nn.xw_plus_b(output, softmax_w, softmax_b) for output in outputs_validation]\n",
    "logits_validation = tf.reshape(tf.split(tf.reshape(logits_validation, [n_input, N_VALIDATION_SET, vocab_size]), N_VALIDATION_SET, 1), \n",
    "                               [N_VALIDATION_SET, n_input, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training loss\n",
    "loss_validation = tf.contrib.seq2seq.sequence_loss(logits_validation, y_validation, weights=tf.ones([N_VALIDATION_SET, n_input], dtype=tf.float32), # check this\n",
    "                                        average_across_timesteps=True, average_across_batch=True)\n",
    "cost_validation = tf.reduce_sum(loss_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tensor flow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity = np.eye(vocab_size)\n",
    "def get_midi_xy(data, midi_file_number):\n",
    "    offset = np.random.randint(0, len(data[midi_file_number]) - n_input - 1)\n",
    "    midi_x = data[midi_file_number][offset:offset+n_input]\n",
    "    midi_y = data[midi_file_number][1 + offset:1 + offset+n_input].reshape(1, n_input)\n",
    "    try:\n",
    "        identity[midi_x.astype(int)], midi_y\n",
    "    except:\n",
    "        print(midi_x)\n",
    "    return identity[midi_x.astype(int)], midi_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data, num_batches):\n",
    "    \"\"\"Generate random batches of x and y training vectors for RNN.\n",
    "       \n",
    "    Returns:\n",
    "        Two batches of x and y vectors.\n",
    "    \"\"\"\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    batch = np.random.choice(range(len(data)), num_batches, replace=True)\n",
    "    for b in batch:\n",
    "        midi_x, midi_y = get_midi_xy(data, b%len(training_data))\n",
    "        batch_x.append(midi_x)\n",
    "        batch_y.append(midi_y)\n",
    "    batch_y = np.reshape(batch_y, [num_batches, n_input])\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seconds_to_minsecstr(seconds):\n",
    "    minutes = seconds//60\n",
    "    seconds -= 60*minutes\n",
    "    if minutes < 10: minutes = \"0\" + str(minutes)\n",
    "    if seconds < 10: seconds = \"0\" + str(seconds)\n",
    "    return str(minutes) + \":\" + str(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter=100, Average Loss=6.436852, Validation Loss=6.058170, Time Elapsed=00:26\n"
     ]
    }
   ],
   "source": [
    "training_loss_list = []\n",
    "validation_loss_list = []\n",
    "time_elapsed_list = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "step = 0\n",
    "loss_total = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while step < training_iters:\n",
    "    start_a = time.time()\n",
    "    \n",
    "    batch_x, batch_y = get_batch(training_data, batch_size)\n",
    "    _, loss = session.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "    loss_total += loss\n",
    "    \n",
    "    if step % validation_step == 0:\n",
    "        batch_x_validation, batch_y_validation = get_batch(validation_data, N_VALIDATION_SET)\n",
    "        loss_validation = session.run([cost_validation], feed_dict={x_validation: batch_x_validation, y_validation: batch_y_validation})[0]\n",
    "    \n",
    "    training_loss_list.append(loss)\n",
    "    validation_loss_list.append(loss_validation)\n",
    "    time_elapsed = seconds_to_minsecstr(int(time.time()-start_time))\n",
    "    time_elapsed_list.append(time_elapsed)\n",
    "    \n",
    "    if (step+1) % display_step == 0:\n",
    "        display = \"Iter=\" + str(step+1) + \", Average Loss={:.6f}, Validation Loss={:.6f}, Time Elapsed={}\".format(\n",
    "            loss_total/display_step, loss_validation, time_elapsed)\n",
    "        print(display)\n",
    "        loss_total = 0\n",
    "        loss_validation_total = 0\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(training_loss_list, label='Training loss')\n",
    "plt.plot(validation_loss_list, label='Validation loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Training/Validation loss over iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logfile_directory = 'logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss_list = np.array(validation_loss_list)\n",
    "min_valid_loss = np.inf\n",
    "min_valid_loss_iteration = -1\n",
    "for i in range(validation_step*10, len(validation_loss_list)-validation_step*10)[::validation_step]:\n",
    "    valid_loss_mean = np.nanmean(validation_loss_list[i-validation_step*10:i+validation_step*10]) # smoothed validation mean\n",
    "    if valid_loss_mean < min_valid_loss:\n",
    "        min_valid_loss = valid_loss_mean\n",
    "        min_valid_loss_iteration = i\n",
    "        \n",
    "train_loss_mean = np.nanmean(np.array(np.array(training_loss_list)[-50:]))\n",
    "valid_loss_mean = np.nanmean(np.array(np.array(validation_loss_list)[-50:]))\n",
    "train_loss_mean, valid_loss_mean\n",
    "\n",
    "min_valid_loss, min_valid_loss_iteration, train_loss_mean, valid_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.strftime(\"%Y-%m-%d %H.%M\")\n",
    "logfile_name =\"Logfile (Date={}, MinValidLoss={:.2f}, TrainLoss={:.2f}, Iterations={}).txt\". \\\n",
    "    format(date, min_valid_loss, train_loss_mean, len(validation_loss_list))\n",
    "logfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = open(logfile_directory + logfile_name, \"w\")\n",
    "\n",
    "logfile.write(\"Training loss={:.6f}\\n\".format(train_loss_mean))\n",
    "logfile.write(\"Validation loss={:.6f}\\n\".format(valid_loss_mean))\n",
    "logfile.write(\"Min Validation loss={:.6f}\\n\".format(min_valid_loss))\n",
    "logfile.write(\"Iteration of min validation loss={}\\n\\n\".format(min_valid_loss_iteration))\n",
    "\n",
    "logfile.write(\"Iterations trained={}\\n\".format(len(time_elapsed_list)))\n",
    "logfile.write(\"Duration={}\\n\\n\".format(time_elapsed_list[-1]))\n",
    "\n",
    "logfile.write(\"Number of training examples={}\\n\".format(len(training_data)))\n",
    "logfile.write(\"Number of validation examples={}\\n\\n\".format(len(validation_data)))\n",
    "\n",
    "\n",
    "logfile.write(\"Batch size={}\\n\".format(batch_size))\n",
    "logfile.write(\"Learning rate={:.6f}\\n\".format(learning_rate))\n",
    "logfile.write(\"Number of input (T)={}\\n\\n\".format(n_input))\n",
    "\n",
    "logfile.write(\"Number of hidden layers={}\\n\".format(n_layers))\n",
    "logfile.write(\"Number of hidden units per year={}\\n\\n\".format(n_hidden))\n",
    "\n",
    "for i in range(len(training_loss_list)):\n",
    "    logfile.write(\"Iter={}, Training Loss={:.6f}, Validation Loss={:.6f}, Time Elapsed={}\\n\".format(\n",
    "            (i+1), training_loss_list[i], validation_loss_list[i], time_elapsed_list[i]))\n",
    "    \n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate music from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_GENERATED_NOTE_VECTORS = 1000\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_placeholder = tf.placeholder(tf.float32, [n_layers, 2, 1, n_hidden])\n",
    "l = tf.unstack(state_placeholder, 2, 0)\n",
    "rnn_tuple_state = tuple([tf.nn.rnn_cell.LSTMStateTuple(l[i][0], l[i][1]) for i in range(n_layers)])\n",
    "\n",
    "outputs_generation, states_generation = rnn.static_rnn(rnn_cell, [x_generation], \n",
    "                                                       initial_state=rnn_tuple_state, dtype=tf.float32)\n",
    "\n",
    "logits_generation = tf.nn.xw_plus_b(outputs_generation[0], softmax_w, softmax_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_note = np.eye(vocab_size)[training_data[int(len(training_data)*np.random.random())][0]]\n",
    "seed_note = np.reshape(seed_note, [1, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_music = [seed_note]\n",
    "saved_state = np.zeros((n_layers, 2, 1, n_hidden))\n",
    "for i in range(N_GENERATED_NOTE_VECTORS):\n",
    "    onehot_pred, new_state = session.run([logits_generation, states_generation], \n",
    "                                         feed_dict={x_generation: generated_music[-1], state_placeholder: saved_state})\n",
    "    saved_state = new_state\n",
    "    next_note = np.zeros(vocab_size)\n",
    "    #index = np.argmax(onehot_pred, 1) # take max probability\n",
    "    softmax_cdf = np.exp(onehot_pred[0]/temperature)/np.sum(np.exp(onehot_pred[0]/temperature))\n",
    "    \n",
    "    if i < 4:\n",
    "        print(\"Previous note:\", generated_music[-1].dot(range(1120)))\n",
    "        print(\"Posterior probability:\", softmax_cdf)\n",
    "        plt.plot(softmax_cdf)\n",
    "        plt.show()\n",
    "        \n",
    "    index = np.random.choice(range(vocab_size), p=softmax_cdf) # choose probabilistically\n",
    "    \n",
    "    next_note[index] = 1\n",
    "    next_note = np.reshape(next_note, [1, vocab_size])\n",
    "    \n",
    "    generated_music.append(next_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.array(generated_music).reshape(N_GENERATED_NOTE_VECTORS+1, vocab_size).dot(np.array(range(vocab_size)))\n",
    "notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert generated music to midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_track_sequences(vector_sequence):\n",
    "    \"\"\"Get note sequences for each track from vector sequence output from RNN.\n",
    "\n",
    "    Args:\n",
    "       vector_sequence: List of one-hot vectors containing 128 * NUM_TRACKS note_on events, 128 * NUM_TRACKS note_off events,\n",
    "        and NUM_TIMESHIFTS timeshift events in intervals of 1/96 of a beat each.\n",
    "       \n",
    "    Returns:\n",
    "        List of track vector sequences.\n",
    "    \"\"\"\n",
    "    track_sequences = [[] for _ in range(NUM_TRACKS)]\n",
    "    start_time = 0\n",
    "    for vector in vector_sequence:\n",
    "        index = vector.index(1)\n",
    "        # vector is a time event.\n",
    "        if index >= NUM_MIDI_PITCHES * 2 * NUM_TRACKS:\n",
    "            num_beats = (index - NUM_MIDI_PITCHES * 2 * NUM_TRACKS + 1) / NUM_TIMESHIFTS\n",
    "            start_time += num_beats\n",
    "        else:\n",
    "            # vector is a note_off event.\n",
    "            if index >= NUM_MIDI_PITCHES * NUM_TRACKS:\n",
    "                note_type = 'note_off'\n",
    "                index -= NUM_MIDI_PITCHES * NUM_TRACKS\n",
    "            # vector is a note_on event.\n",
    "            else:\n",
    "                note_type = 'note_on'\n",
    "            track_num = int(index / NUM_MIDI_PITCHES)\n",
    "            note = index % NUM_MIDI_PITCHES\n",
    "            track_sequences[track_num].append({\"type\": note_type, \"note\": note, \"start_time\": start_time})\n",
    "            time_delay = 0\n",
    "            \n",
    "    return track_sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_midi_from_vector_sequence(track_sequences):\n",
    "    \"\"\"Get midi from track sequences.\n",
    "\n",
    "    Args:\n",
    "       track_sequences: List of vector sequences for each track.\n",
    "       \n",
    "    Returns:\n",
    "        MidiFile object.\n",
    "    \"\"\"\n",
    "    mid = mido.MidiFile()\n",
    "    tracks = [mido.MidiTrack() for _ in range(NUM_TRACKS)]\n",
    "    mid.tracks.extend(tracks)\n",
    "\n",
    "    for i, ts in enumerate(track_sequences):\n",
    "        prev_start_time = 0\n",
    "        for event in ts:\n",
    "            time = event[\"start_time\"] - prev_start_time\n",
    "            prev_start_time = event[\"start_time\"]\n",
    "            # I picked a random number for velocity.\n",
    "            mid.tracks[i].append(mido.Message(event[\"type\"], note=event[\"note\"], velocity=50,\n",
    "                                              time=int(time * TICKS_PER_BEAT)))\n",
    "    \n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_sequence = get_track_sequences([list(x[0]) for x in generated_music])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = get_midi_from_vector_sequence(track_sequence)\n",
    "midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generation_output = \"generated_music/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_name = \"Generated Music (Date={}, Temperature={}, Length={}, MinValidLoss={:.2f}, TrainLoss={:.2f}, Iterations={}).mid\". \\\n",
    "    format(date, temperature, N_GENERATED_NOTE_VECTORS, min_valid_loss, train_loss_mean, len(validation_loss_list))\n",
    "midi_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midi.save(generation_output + midi_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
